{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8479f56f",
   "metadata": {},
   "source": [
    "# Tutorial: Using The OpenAI API for Categorization and Labeling\n",
    "### Author: Campbell Lund\n",
    "### 9/26/2023\n",
    "This notebook walks through how to get started using the OpenAI API. We use the specific example of labeling and categorizing sentences to illustrate the capabilities and techniques, such as one-shot learning and chain of thought prompting, of `gpt-3.5-turbo` for text analysis.\n",
    "\n",
    "### Table of contents:\n",
    "- 1. [Initialization](#sec1)\n",
    "- 2. [Example: prompting the model and zero-shot learning](#sec2)\n",
    "    - 2.1.[Converting text to Python lists](#sec2p1)\n",
    "- 3. [Example: prompting the model and one-shot learning](#sec3)\n",
    "- 4. [Example: prompting in batches](#sec4)\n",
    "    - 4.1.[Determining unique categories](#sec4p1)\n",
    "- 5. [Categorizing](#sec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa786973",
   "metadata": {},
   "source": [
    "## 1. Initialization <a name=\"sec1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8e978",
   "metadata": {},
   "source": [
    "Import or `!pip install` the following libraries. For security, I've stored my API key in a `.env` file since this notebook will be shared. Instructions for generating your personal API key can be found [here.](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key) If you don't wish to store your key in a `.env` file, simply set `openai.api_key` equal to your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c8abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "# for exponential backoff\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  \n",
    "# retrieving our API key from a secure file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4ba44",
   "metadata": {},
   "source": [
    "### helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580d0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the model's response to a given message query\n",
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, # degree of randomness\n",
    "                                 max_tokens=150): #4000 is max for input and response combined\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75fd54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/allQueries.csv', header=None, names=[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fefbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rock melting in india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>free energy machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levitation devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flat earthers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who killed jfk?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>biblical cosmology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>mud flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>geoengineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>covid tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>ivermectin use for covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>628 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sentences\n",
       "0       rock melting in india\n",
       "1        free energy machines\n",
       "2          levitation devices\n",
       "3               flat earthers\n",
       "4             who killed jfk?\n",
       "..                        ...\n",
       "623        biblical cosmology\n",
       "624                 mud flood\n",
       "625            geoengineering\n",
       "626               covid tests\n",
       "627  ivermectin use for covid\n",
       "\n",
       "[628 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0100d58",
   "metadata": {},
   "source": [
    "## 2. Ex: prompting the model and zero-shot learning <a name=\"sec2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3560eb5",
   "metadata": {},
   "source": [
    "Now that we have a helper function to send queries and receive responses from the model, we must engineer our prompt. This is where trial and error is really your friend. The model can handle fairly complex instructions, but it's best to be direct. My advice for engineering a successful prompt is to pretend you're writing pseudo-code rather than giving written instructions to a friend - remember it's a computer you're training, not a person.\n",
    "\n",
    "### Vocab:\n",
    "- **zero-shot learning:** a ML paradigm for when a model is applied to objects or concepts it has never seen in training. Since we do not provide labeled examples to ChatGPT for fine-tuning the model, the below is an example of zero-shot learning. \n",
    "- **delimiter:** a character used to indicate the start of a new message.\n",
    "- **token:** a unit of text that the model processes. Tokens are usually individual words, but complex words may be made up of multiple tokens. For our purposes, think of tokens as the number of words in a query or a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d905cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good delimiter since it counts as a single token and isn't likely to appear naturally in the message\n",
    "delimiter = \"####\" \n",
    "\n",
    "# message given to the model with instructions for how to respond\n",
    "system_message = f\"\"\"\n",
    "Your job is to determine the topic of a given sentence. \\\n",
    "You will be given a sentence as input and you will return \\\n",
    "a single word that best represents the topic of the sentence. \\\n",
    "Each input will be delimited by {delimiter} characters. \\\n",
    "Output a Python list of objects where each object has the following format: \\\n",
    "    \"Sentence\": <the input sentence>, \\\n",
    "    \"Topic\": <the topic output> \\\n",
    "\"\"\"\n",
    "# message input from the user\n",
    "user_message = f\"\"\"\\\n",
    "rock melting in india \\\n",
    "{delimiter}\n",
    "free energy machines \\\n",
    "{delimiter}\n",
    "levitation devices \\\n",
    "\"\"\"\n",
    "\n",
    "# combining the system and user messages to give as input to our helper function\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},    \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cac335",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion_from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d745a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"Sentence\": \"rock melting in india\", \"Topic\": \"rock\"}, {\"Sentence\": \"free energy machines\", \"Topic\": \"energy\"}, {\"Sentence\": \"levitation devices\", \"Topic\": \"levitation\"}]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f7c3d",
   "metadata": {},
   "source": [
    "Although the output apprears to be a Python list as we instructed the model, note that all output from our helper function will be a string which we must convert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4ac20",
   "metadata": {},
   "source": [
    "## 2.1. Converting text to Python sets <a name=\"sec2p1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a30b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2384ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Sentence': 'rock melting in india', 'Topic': 'rock'},\n",
       " {'Sentence': 'free energy machines', 'Topic': 'energy'},\n",
       " {'Sentence': 'levitation devices', 'Topic': 'levitation'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710d779",
   "metadata": {},
   "source": [
    "Now we have an actual array of objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527478e",
   "metadata": {},
   "source": [
    "## 3. Ex: prompting the model and one-shot learning <a name=\"sec3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101415b",
   "metadata": {},
   "source": [
    "For more complex tasks, or if the model just isn't returning what you expect, examples may need to be provided. \n",
    "### Vocab:\n",
    "- **one-shot learning:** a ML paradigm for when a model is trained to handle objects or concepts based on a very limited amount of training data. Below, we provide two examples of input and expected output to fine-tune our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2bbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#providing examples of correct outputs to improve model accuracy\n",
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": \"rock melting in india\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"{\\\"Sentence\\\": \\\"rock melting in india\\\", \\\"Topic\\\": \\\"melting\\\"}\"},\n",
    "    {\"role\": \"user\", \"content\": \"free energy machines\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"{\\\"Sentence\\\": \\\"free energy machines\\\", \\\"Topic\\\": \\\"machines\\\"}\"}\n",
    "      ]\n",
    "    \n",
    "# using the same user system and message as defined in section 2\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content': system_message},    \n",
    "{'role':'user', \n",
    " 'content': f\"{delimiter}{user_message}{delimiter}\"},  \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fd9507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Sentence\": \"rock melting in india\", \"Topic\": \"melting\"}, {\"Sentence\": \"free energy machines\", \"Topic\": \"machines\"}, {\"Sentence\": \"levitation devices\", \"Topic\": \"devices\"}]\n"
     ]
    }
   ],
   "source": [
    "# providing both the examples and the previous messages as input\n",
    "response = get_completion_from_messages(examples + messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda81380",
   "metadata": {},
   "source": [
    "Notice how the third topic changes after providing examples for the first two inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b7a93",
   "metadata": {},
   "source": [
    "## 4. Ex: prompting in batches <a name=\"sec4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa8181",
   "metadata": {},
   "source": [
    "Often when we use the OpenAI API it is because we have large amounts of data that we want to use as prompts. Entering these queries by hand is time-consuming, so let's automate the process. Some important notes:\n",
    "\n",
    "Our API account has both a `rate_limit` and a `max_tokens` value. The `max_tokens` is 4000 tokens for both the user message and the generated response. This means the combined input and output for each query must be less than 4000 tokens. This is one of the reasons we will break up large tasks into smaller parts.\n",
    "\n",
    "Another reason is to stay within the `rate_limit`. To determine the rate limit of your account, simply try running the old`get_completion_from_messages()` helper function on a large data frame. It won't be long until you receive this message:\n",
    "\n",
    "`RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-KiUYu8NRxzHi3TljuvYUEiIG on tokens per min. Limit: 90000 / min. Current: 87379 / min. Contact us through our help center at help.openai.com if you continue to have issues.`\n",
    "\n",
    "Now we know our `rate_limit` is 9000 tokens/min."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23bc01",
   "metadata": {},
   "source": [
    "### helper function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc2858",
   "metadata": {},
   "source": [
    "The below helper function is similar to the previous `get_completion_from_messages()` except now we ask for a `df`, `system_message`, and `batch_size` as parameters. `get_completion_from_messages_batch()` will query each row of the provided `df` in batches of `batch_size` to the model and return an array of all responses. If your results are inaccurate, try lowering `batch_size` and if it's taking too long, raise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf1169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an array containing the model's responses from a given df of message queries\n",
    "@retry(wait=wait_random_exponential(min=30, max=60), stop=stop_after_attempt(6))\n",
    "def get_completion_from_messages_batch(df,\n",
    "                                 system_message,\n",
    "                                 batch_size,\n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, # degree of randomness\n",
    "                                 max_tokens=300): # 4000 is max for input and response combined\n",
    "    \n",
    "    responses = []\n",
    "    delimiter = '####'\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        user_message = \"\"\n",
    "        for index, row in batch.iterrows():\n",
    "            user_message += f\"{row['sentences']}{delimiter}\"\n",
    "            \n",
    "        messages = [  \n",
    "        {'role':'system', \n",
    "         'content': system_message},    \n",
    "        {'role':'user', \n",
    "         'content': user_message}  \n",
    "        ] \n",
    "        \n",
    "        # calculate sleep time before each request to ensure we don't exceed the rate limit\n",
    "        # calculate_sleep_time() # comment out to test your account's rate limit\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature, \n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message[\"content\"]\n",
    "        responses.append(content) \n",
    "        \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c28a40",
   "metadata": {},
   "source": [
    "### engineering a new prompt:\n",
    "This prompt will be applied to our entire `df`. Try to keep it simple to speed things up. Since LLMs are already trained to do summarization tasks, we'll start our categorization by asking the model to determine the subject of each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "054e6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "system_message = f\"\"\"\n",
    "    The goal is to classify sentences based on their topic.\\\n",
    "    Your job is to determine the topic of a given sentence. \\\n",
    "    You will be given a sentence as input and you will return \\\n",
    "    a single word that best represents the topic of the sentence. \\\n",
    "    Be broad with the topics, some sentences should share \\\n",
    "    similar topics and it is okay to return the same topic\\\n",
    "    multiple times. Each input will be delimited by {delimiter} \\\n",
    "    characters. Format your response as a Python list, each \\\n",
    "    topic must be in double quotations. \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbd58d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = get_completion_from_messages_batch(df, system_message, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fba66b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"conspiracy theories\", \"bilderberg\", \"trump conspiracy theories\", \"gun control conspiracy theories\", \"crazy conspiracy theories\", \"9/11 hoaxes\", \"looking for bigfoot\", \"big government\", \"great reset\", \"voting scams\", \"elvis is alive\", \"moon landing did not happen\", \"jfk conspiracy\", \"have we been visited by other life forms\", \"was 9/11 allowed to happen by our own government\", \"fault\", \"untrue\", \"have aliens been to earth\", \"area 51\", \"mlk fbi\", \"mlk killed by govt\", \"mlk conspiracy\", \"john f kennedy\", \"ufos\", \"paranormal\", \"kennedy assassination\", \"climate change\", \"celebrity clones\", \"roswell crash conspiracy\", \"government conspiracies\", \"twin tower theories\", \"ufo & government\", \"shadow government\", \"russia collusion\", \"john kennedy\", \"assassination\", \"president\", \"government is hiding information\", \"covid vaccine implanting chips\", \"secret aliens on planets\", \"alex jones\", \"globalist agenda\", \"sandy hook shooting actors\", \"theories that are a conspiracy\", \"spare change\", \"covid 19 origins\", \"covid made by china lab\", \"covid escaped lab\", \"covid shot magnetic\", \"celebs are lizards\", \"top conspiracy theories\",]\n",
      "[\"covid-19 conspiracy theories\", \"government conspiracy theories\", \"chem trails\", \"project bluebeam\", \"most believed conspiracy theories\", \"big conspiracy theories\", \"unbelievable stories\", \"myths that persist\", \"okc bombing second suspect\", \"timothy mcveigh black ops\", \"aberration in the heartland of the real: the secret lives of timothy mcveigh\" by wendy s. painting, phd\", \"hawaii chemtrails\", \"pizzagate adrenochrome\", \"vaccine bloody spikes\", \"man on the moon\", \"obama birth certificate\", \"covid origin\", \"911\", \"what is in area 51\", \"did the us government plan 9/11\", \"why did the us government kill martin luther king jr.\", \"911 plane crash\", \"ufo sightings\", \"covid\", \"government\", \"origin of q\", \"scientific evidence\", \"educational level\", \"didn't go the moon....and that is true\", \"unrelenting body odor from leftist nutjob females that is impossible to cover up\", \"redlining\", \"gerrymandering\", \"russian tampering of the 2016 election\", \"john f. kennedy's assassination\", \"roswell crash & cover-up\", \"protocols of the elders of zion\", \"unsolved mysteries\", \"ancient aliens\", \"vaccine tracking\", \"nazi moon bases\", \"j]\n",
      "[\"conspiracies\", \"government control\", \"president body double\", \"stock market scam\", \"kennedy death\", \"q anon\", \"aliens\", \"ping pong ball conspiracy\", \"marilyn monroe and the kennedy's\", \"vaccine misinformation\", \"ghosts\", \"mlb rigged\", \"psychological research on conspiracy theories\", \"unknown\", \"9/11/2001\", \"2020 vote\", \"election\", \"false flag\", \"5g\", \"covid vaccine conspiracy\", \"moon landing\", \"jfk assassination\", \"epstein alive\", \"natural disasters\", \"ufo disclosure\", \"cia false flags\", \"illuminati\", \"secret societies\", \"bigfoot\", \"chemtrail evidence\", \"government chip evidence\", \"annunaki\", \"election interference\", \"voter fraud\", \"voter interference\", \"area 51\", \"roswell aliens\", \"cia alien coverup\", \"tucker carlson\", \"vaxxer\", \"sheep\", \"moon landing faked\", \"covid and 5g\", \"political\", \"plot\", \"dorothy kilgallen cause of death\", \"existence of aliens\", \"vaccination fears\", \"migrant caravan\", \"911 conspiracy\", \"trump russia conspiracy\", \"national security agency\", \"project bluebook\", \"project mk ultra\", \"tupac death\", \"hitler death\", \"trump haters\",]\n",
      "[\"911 conspiracy theory\", \"alien conspiracy theory\", \"illuminati conspiracy theory\", \"who shot john f. kennedy?\", \"did we really land on the moon?\", \"was the government involved in the 911 attacks?\", \"wuhan lab leak theory\", \"building 7 mystery\", \"missing funds from 911\", \"bohemian grove\", \"human-et contact/ufos\", \"occult\", \"mystery\", \"government secrets\", \"controlling the world\", \"chem trails\", \"non vacciners\", \"paul mccartney switch\", \"walt disney frozen\", \"kennedy assassination cia\", \"con trails\", \"russiagate\", \"vaccine\", \"secret government\", \"jefferey epstein\", \"edward snowden\", \"trumps\", \"clinton\", \"comtrails\", \"space travel\", \"jfk alive\", \"qanon beliefs\", \"real conspiracy theories\", \"debunked conspiracies\", \"2020 election fraud\", \"september 11th conspiracy\", \"fema tents\", \"election fraud\", \"simulation theory\", \"kennedy grassy knoll\", \"ukraine biolabs\", \"covid made in a lab\", \"landing on the moon\", \"jfk assignation\", \"vaccine problems\", \"alien coverup\", \"if the moon landing is real\", \"roswell crash and cover up with aliens\", \"satanic]\n",
      "[\"Flat Earth\", \"QAnon\", \"JFK Death\", \"Wayfair Pedophile\", \"COVID-19\", \"Crisis Actors\", \"Aliens Existence\", \"911 Inside Job\", \"MK Ultra\", \"Hidden Government Secrets\", \"Sandy Hook\", \"Bavarian Illuminati\", \"Judge Daniel Paul Schreber\", \"JFK Jr Trump Rally\", \"Presidential Election Fraud\", \"Moon Landing\", \"Hunter's Laptop\", \"Wuhan Lab Leak\", \"Paul McCartney Dead\", \"Reptile People\", \"Republican\", \"TikTok\", \"Area 54\", \"Conspiracy Documentary\", \"Coronavirus\", \"New World Order\", \"Pizzagate\", \"Anthony Bourdain Murder\", \"Covid Vaccines and Chips\", \"Secret Alien\", \"Vaccine Hoax\", \"Mind Control Weapon\", \"Secret Biolabs\", \"Government Spying\", \"Cloud Seeding\", \"Red Cross Scam\", \"Barrel Oil Conspiracies\", \"Bigfoot\", \"Bermuda Triangle\", \"Inflation\", \"War\", \"Jet Fuel\", \"JFK Jr\", \"Election Stolen\", \"Stock Market Rigged\", \"Drug Company Vaccine Scam\", \"Moon Walk\", \"Q-Anon\", \"Skinwalker Ranch\", \"Flat Earth Belief\", \"Weird Theories\", \"Scary Theories\", \"Vaccination Risks\", \"NBA Draft Frozen Envelope\", \"Paul McCartney Car Crash Death\",]\n",
      "[\"conspiracy theories\", \"assassination\", \"cryptozoology\", \"COVID-19\", \"politics\", \"airport\", \"technology\", \"vaccines\", \"pedophilia\", \"secret societies\", \"hoaxes\", \"elections\", \"science\", \"cosmology\", \"history\", \"geoengineering\", \"medicine\"]\n"
     ]
    }
   ],
   "source": [
    "# format string\n",
    "formatted_responses = []\n",
    "for i, r in enumerate(responses):\n",
    "    if r[len(r)-1] != \"]\":\n",
    "        responses[i] += \"]\"\n",
    "    print(responses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12992bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[\"conspiracy theories\", \"government coverup\", \"JFK assassination\", \"moon landing hoax\", \"aliens and UFOs\", \"COVID-19 vaccine misconceptions\", \"9/11 conspiracy\", \"Flat Earth theory\", \"secret societies\", \"COVID-19 origins\"]',\n",
       " '[\"conspiracy theories\",\"government\",\"9/11\",\"aliens\",\"moon landing\",\"JFK assassination\",\"COVID-19\",\"vaccines\",\"celebrity clones\",\"Roswell UFO\",\"lizard men\",\"one world order\",\"election conspiracy\",\"flat earth\",\"secret society\",\"Philadelphia experiment\",\"hydroxychloroquine\",\"Pizzagate\",\"Q drops\",\"Epstein\",\"Bigfoot\"]',\n",
       " '[\"covid-19 conspiracy theories\",\"government conspiracy theories\",\"chem trails\",\"project bluebeam\",\"most believed conspiracy theories\",\"big conspiracy theories\",\"unbelievable stories\",\"myths that persist\",\"okc bombing second suspect\",\"timothy mcveigh black ops\",\"aberration in the heartland of the real: the secret lives of timothy mcveigh\" by wendy s. painting, phd\",\"hawaii chemtrails\",\"pizzagate adrenochrome\",\"vaccine bloody spikes\",\"man on the moon\",\"obama birth certificate\",\"covid origin\",\"911\",\"what is in area 51\",\"did the us government plan 9/11\",\"why did the us government kill martin luther king jr.\",\"911 plane crash\",\"ufo sightings\",\"covid\",\"government\",\"origin of q\",\"scientific evidence\",\"educational level\",\"didn\\'t go the moon....and that is true\",\"unrelenting body odor from leftist nutjob females that is impossible to cover up\",\"redlining\",\"gerrymandering\",\"russian tampering of the 2016 election\",\"john f. kennedy\\'s assassination\",\"roswell crash & cover-up\",\"protocols of the elders of zion\",\"unsolved mysteries\",\"ancient aliens\",\"vaccine tracking\",\"nazi moon bases\",\"jews are aliens\",\"government did 911\",\"plandemic\",\"china tik tok dumbing down other countries\",\"usa democrats are owned by chinese\",\"jfk was assassinated by powerful forces in the',\n",
       " '[\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies\",\"conspiracies',\n",
       " '[\"911 conspiracy theory\",\"alien conspiracy theory\",\"illuminati conspiracy theory\",\"JFK assassination\",\"moon landing\",\"government involvement in 911 attacks\",\"Wuhan lab leak theory\",\"Building 7 mystery\",\"missing funds from 911\",\"Bohemian Grove\",\"human-ET contact/UFOS\",\"occult\",\"mystery\",\"government secrets\",\"controlling the world\",\"chem trails\",\"non vacciners\",\"Paul McCartney switch\",\"Walt Disney frozen\",\"CIA involvement in Kennedy assassination\",\"con trails\",\"Russiagate\",\"vaccine\",\"secret government\",\"Jeffrey Epstein\",\"Edward Snowden\",\"Trump\",\"Clinton\",\"space travel\",\"QAnon beliefs\",\"real conspiracy theories\",\"debunked conspiracies\",\"2020 election fraud\",\"September 11th conspiracy\",\"FEMA tents\",\"election fraud\",\"simulation theory\",\"Ukraine biolabs\",\"COVID made in a lab\",\"JFK alive\",\"Roswell crash and cover-up with aliens\",\"satanic panic\",\"hidden aliens\",\"election stolen from Trump\",\"COVID was planned\",\"Ukraine connection Biden\",\"George Soros\",\"Michelle Obama male\",\"hydroxychloroquine\",\"Bill Gates vaccine\",\"the world is ending soon\",\"no racism\",\"everyone is hateful\",\"Princess Diana\\'s death\",\"Roswell crash and cover-up\",\"rogue\",\"voting fraud\",\"UFO cover-ups\",\"Jewish space lasers\",\"illegal immigrants allowed to vote\",\"Elvis is still alive\",\"Area 52\",\"coronavirus made in a lab\",\"free will doesn\\'t exist\",\"crack epidemic government',\n",
       " '[\"conspiracy\", \"QAnon\", \"JFK assassination\", \"pedophile\", \"COVID-19\", \"school shootings\", \"aliens\", \"9/11\", \"MK Ultra\", \"election\", \"government secrets\", \"Sandy Hook\", \"Bavarian Illuminati\", \"Judge Daniel Paul Schreber\", \"moon landing\", \"Hunter\\'s laptop\", \"Wuhan lab leak\", \"Paul McCartney death\", \"reptile people\", \"Republican\", \"TikTok\", \"Area 51\", \"coronavirus\", \"New World Order\", \"Pizzagate\", \"Anthony Bourdain murder\", \"vaccine hoax\", \"mind control\", \"secret biolabs\", \"government spying\", \"cloud seeding\", \"Red Cross scam\", \"oil conspiracies\", \"Bigfoot\", \"Bermuda Triangle\", \"inflation\", \"war\", \"QAnon\", \"COVID-19\", \"drug company vaccine scam\", \"moon landing\", \"QAnon\", \"Skinwalker Ranch\", \"flat Earth\", \"weird theories\", \"scary theories\", \"COVID-19\", \"vaccinations\", \"NBA draft\", \"Paul McCartney car crash\", \"JFK assassination\", \"Planet X\", \"weather control\", \"alien life\", \"time travelers\", \"lost cosmonauts\", \"9/11\", \"stock market\", \"rigged elections\", \"JFK assassination\", \"white genocide\", \"Las Vegas shooting\", \"St',\n",
       " '[\"conspiracy theories\", \"conspiracy theories\", \"COVID-19\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"technology\", \"technology\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"COVID-19\", \"2020 election\", \"conspiracy theories\", \"COVID-19\", \"COVID-19\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"conspiracy theories\", \"COVID-19\", \"COVID-19\"]']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb9b0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"conspiracy theories\", \"bilderberg\", \"trump conspiracy theories\", \"gun control conspiracy theories\", \"crazy conspiracy theories\", \"9/11 hoaxes\", \"looking for bigfoot\", \"big government\", \"great reset\", \"voting scams\", \"elvis is alive\", \"moon landing did not happen\", \"jfk conspiracy\", \"have we been visited by other life forms\", \"was 9/11 allowed to happen by our own government\", \"fault\", \"untrue\", \"have aliens been to earth\", \"area 51\", \"mlk fbi\", \"mlk killed by govt\", \"mlk conspiracy\", \"john f kennedy\", \"ufos\", \"paranormal\", \"kennedy assassination\", \"climate change\", \"celebrity clones\", \"roswell crash conspiracy\", \"government conspiracies\", \"twin tower theories\", \"ufo & government\", \"shadow government\", \"russia collusion\", \"john kennedy\", \"assassination\", \"president\", \"government is hiding information\", \"covid vaccine implanting chips\", \"secret aliens on planets\", \"alex jones\", \"globalist agenda\", \"sandy hook shooting actors\", \"theories that are a conspiracy\", \"spare change\", \"covid 19 origins\", \"covid made by china lab\", \"covid escaped lab\", \"covid shot magnetic\", \"celebs are lizards\", \"top conspiracy theories\",]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f7c87",
   "metadata": {},
   "source": [
    "## 4.1. Determining unique categories <a name=\"sec4p1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5c565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading allTopics.csv - run this cell only if you're working with the saved data\n",
    "temp = pd.read_csv('data/allTopics.csv', skiprows=1, names=[\"topics\"])\n",
    "\n",
    "all_topics = []\n",
    "temp = temp.values.tolist()\n",
    "for t in temp:\n",
    "    all_topics.append(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61cf420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = [string.lower() for string in all_topics if len(string.split()) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70879457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique topics:  42\n",
      "Topics:  ['9/11', 'cryptozoology', 'astronomy', 'cryptid', 'sustainability', 'science', 'politics', 'money', 'paranormal', 'environment', 'surveillance', 'food', 'aliens', 'conference', 'health', 'animals', 'uncategorized', 'extraterrestrial', 'entertainment', 'space', 'government', 'supernatural', 'history', 'crime', 'memory', 'misinformation', 'ufos', 'geology', 'economy', 'problem', 'sports', 'tragedy', 'mystery', 'false', 'terrorism', 'aviation', 'scandal', 'media', 'technology', 'error', 'pandemic', 'conspiracy']\n"
     ]
    }
   ],
   "source": [
    "unique_topics = list(set(all_topics))\n",
    "print('Number of unique topics: ', len(unique_topics))\n",
    "print('Topics: ', unique_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59880c3",
   "metadata": {},
   "source": [
    "Since there are a reasonable number of unique topics, I'll narrow down the most relevant final categories by hand. You can prompt the LLM to do this or use another NLP technique if you wish. I discerned 12 major categories as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9948fe",
   "metadata": {},
   "source": [
    "1. 'politics'\n",
    "    - 'government'\n",
    "    - 'scandal'\n",
    "    - 'misinformation'\n",
    "    - 'surveillance'\n",
    "    - 'crime'\n",
    "2. 'health'\n",
    "\t- 'pandemic'\n",
    "3. 'terrorism'\n",
    "\t- '9/11'\n",
    "    - 'tragedy'\n",
    "4. 'media'\n",
    "\t- 'entertainment'\n",
    "5. 'economy'\n",
    "\t- 'money'\n",
    "6. 'history'\n",
    "7. 'environment'\n",
    "\t- 'sustainability'\n",
    "8. 'science'\n",
    "\t- 'geology'\n",
    "9. 'technology'\n",
    "\t- 'aviation'\n",
    "10. 'conspiracy'\n",
    "\t- 'false'\n",
    "11. 'space'\n",
    "\t- 'paranormal'\n",
    "    - 'extraterrestrial'\n",
    "    - 'aliens'\n",
    "    - 'astronomy'\n",
    "    - 'ufos'\n",
    "12. 'supernatural'\n",
    "\t- 'cryptid'\n",
    "    - 'cryptozoology'\n",
    "    - 'mystery'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde67ab",
   "metadata": {},
   "source": [
    "## 5. Categorizing  <a name=\"sec5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443e68e",
   "metadata": {},
   "source": [
    "In this section, we're using the output from a previous query as the input to another. This is called **chain of thought prompting**. For complex tasks, it's necessary to break problems down into digestible parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfd6ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "    Your job is to classify sentences based on their topic.\\\n",
    "    Given a sentence, determine which category it belongs \\\n",
    "    to from the topic list. \\\n",
    "        Topic list: \\\n",
    "            [politics, \\\n",
    "            health, \\\n",
    "            terrorism, \\\n",
    "            media, \\\n",
    "            economy, \\\n",
    "            history, \\\n",
    "            environment, \\\n",
    "            science, \\\n",
    "            technology, \\\n",
    "            space, \\\n",
    "            supernatural] \\  \n",
    "    Each input will be delimited by #### characters. \\\n",
    "    Format your response as a Python list. Output a Python \\\n",
    "    object of the following format: \\\n",
    "    \"topic\": <the determined topic from the Topic List>, \\\n",
    "    \"sentence\": <the input sentence> \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "350c296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = get_completion_from_messages_batch(df, system_message, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25f6fcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[{\"topic\": \"supernatural\", \"sentence\": \"rock melting in india\"}, {\"topic\": \"technology\", \"sentence\": \"free energy machines\"}, {\"topic\": \"supernatural\", \"sentence\": \"levitation devices\"}, {\"topic\": \"supernatural\", \"sentence\": \"flat earthers\"}, {\"topic\": \"histo...{\"topic\": \"science\", \"sentence\": \"global warming\"}, {\"topic\": \"supernatural\", \"sentence\": \"aliens exist\"}, {\"topic\": \"conspiracies\", \"sentence\": \"911 is fake\"}, {\"topic\": \"space\", \"sentence\": \"us did not land on the moon\"}, {\"topic\": \"economy\", \"sentence\": \"fed conspiracies\"}, {\"topic\": \"conspiracies\", \"sentence\": \"9/11 truth\"}]',\n",
       " '[{\"topic\": \"conspiracy\", \"sentence\": \"bilderberg\"}, {\"topic\": \"conspiracy\", \"sentence\": \"trump conspiracy theories\"}, {\"topic\": \"conspiracy\", \"sentence\": \"gun control conspiracy theories\"}, {\"topic\": \"conspiracy\", \"sentence\": \"crazy conspiracy theories\"}, {\"topic\": \"conspiracy\", \"sentence\": \"9/11 hoaxes\"}, {\"topic\": \"supernatural\", \"sentence\": \"looking for bigfoot\"}, {\"topic\": \"politics\", \"sentence\": \"big government\"}, {\"topic\": \"conspiracy\", \"sentence\": \"great reset\"}, {\"topic\": \"conspiracy\", \"sentence\": \"voting scams\"}, {\"topic\": \"supernatural\", \"sentence\": \"elvis is alive\"}, {\"topic\": \"conspiracy\", \"sentence\": \"moon landing did not happen\"}, {\"topic\": \"conspiracy\", \"sentence\": \"jfk conspiracy\"}, {\"topic\": \"supernatural\", \"sentence\": \"have we been visited by other life forms\"}, {\"topic\": \"conspiracy\", \"sentence\": \"was 9/11 allowed to happen by our own government\"}, {\"topic\": \"conspiracy\", \"sentence\": \"conspiracy\"}, {\"topic\": \"fault\", \"sentence\": \"untrue\"}, {\"topic\": \"supernatural\", \"sentence\": \"have aliens been to earth\"}, {\"topic\": \"conspiracy\", \"sentence\": \"area 51\"}, {\"topic\": \"conspiracy',\n",
       " '[{\"topic\": \"conspiracy theories\", \"sentence\": \"covid-19 conpsiracy theories\"}, {\"topic\": \"conspiracy theories\", \"sentence\": \"government conspiracy theories\"}, {\"topic\": \"conspiracy theories\", \"sentence\": \"what are chem trails?\"}, {\"topic\": \"conspiracy theories\",...',\n",
       " '[{\"topic\": \"supernatural\", \"sentence\": \"area 41\"}, {\"topic\": \"supernatural\", \"sentence\": \"illuminate\"}, {\"topic\": \"conspiracy\", \"sentence\": \"society conspiracies\"}, {\"topic\": \"terrorism\", \"sentence\": \"9/11 was an inside job\"}, {\"topic\": \"terrorism\", \"sentence... \"sentence\": \"vaccine death\"}, {\"topic\": \"politics\", \"sentence\": \"votes faked\"}, {\"topic\": \"health\", \"sentence\": \"covid not real\"}, {\"topic\": \"history\", \"sentence\": \"princess diana murder theories\"}, {\"topic\": \"history\", \"sentence\": \"kennedy assassination theories\"}]',\n",
       " '[{\"topic\": \"conspiracy theory\", \"sentence\": \"911 conspiracy theory\"}, {\"topic\": \"conspiracy theory\", \"sentence\": \"alien conspiracy theory\"}, {\"topic\": \"conspiracy theory\", \"sentence\": \"illuminati conspiracy theory\"}, {\"topic\": \"conspiracy theory\", \"sentence...',\n",
       " '[{\"topic\": \"supernatural\", \"sentence\": \"flat earth proof\"}, {\"topic\": \"supernatural\", \"sentence\": \"qanon evidence\"}, {\"topic\": \"history\", \"sentence\": \"jfk death\"}, {\"topic\": \"supernatural\", \"sentence\": \"wayfair pedophile\"}, {\"topic\": \"politics\", \"sentence\": \"c...',\n",
       " '[{\"topic\": \"history\", \"sentence\": \"jfk asassination\"}, {\"topic\": \"supernatural\", \"sentence\": \"sasquatch\"}, {\"topic\": \"health\", \"sentence\": \"hydrochloroquin efficacy against covid\"}, {\"topic\": \"politics\", \"sentence\": \"hunter biden\\'s laptop\"}, {\"topic\": \"supern...']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935dc39",
   "metadata": {},
   "source": [
    "Once you've fine-tuned the prompt to your liking, run `get_completion_from_messages_batch()` on your entire `df`. This will take a long time to compile. A way to speed it up is to try lowering the batch size, either with a loop as we did before in `Section 4.1` or manually slicing the df."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
